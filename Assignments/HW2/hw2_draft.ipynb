{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "#import logz_pytorch as logz\n",
    "import logz\n",
    "import scipy.signal\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#============================================================================================#\n",
    "# Utilities\n",
    "#============================================================================================#\n",
    "\n",
    "\n",
    "def pathlength(path):\n",
    "    return len(path[\"reward\"])\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    # ========================================================================================#\n",
    "    #                           ----------SECTION 3----------\n",
    "    # Network building\n",
    "    #\n",
    "    # Your code should make a feedforward neural network (also called a multilayer perceptron)\n",
    "    # with 'n_layers' hidden layers of size 'size' units.\n",
    "    #\n",
    "    # The output layer should have size 'output_size' and activation 'output_activation'.\n",
    "    #\n",
    "    # ========================================================================================#\n",
    "\n",
    "    def __init__(self, input_size, output_size, n_layers=2, size=64, activation=F.tanh, output_activation=None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout_rate = 0.3\n",
    "        self.fc1 = nn.Linear(input_size, size)\n",
    "        self.fc2 = nn.Linear(size, size)\n",
    "        self.fc3 = nn.Linear(size, output_size)\n",
    "#         self.fc = (\n",
    "#             [nn.Linear(input_size, size)] + \n",
    "#             [nn.Linear(size, size)] * n_layers + \n",
    "#             [nn.Linear(size, output_size)]\n",
    "#         )\n",
    "        self.drop = nn.Dropout(p = self.dropout_rate)\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "\n",
    "    # assert output_activation is None, 'output activation must be None, other options not implemented'\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))  \n",
    "        x = self.activation(self.fc2(x))  \n",
    "        if self.output_activation is None:\n",
    "            x = self.fc3(x)                      # Last layer \n",
    "        else:\n",
    "            x = self.output_activation(self.fc3(x))  \n",
    "        \n",
    "#         x = self.activation(self.fc[0](x))\n",
    "#         for layer in self.fc[1:-1]:\n",
    "#             x = self.activation(layer(x))     # Hidden layers\n",
    "#         if self.output_activation is None:\n",
    "#             x = self.fc[-1](x)                      # Last layer \n",
    "#         else:\n",
    "#             x = self.output_activation(self.fc[-1](x))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def set_dropout_rate(self, p):\n",
    "        self.dropout_rate = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-27 20:55:26,844] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with seed 1\n",
      "\u001b[32;1mLogging data to data/sb_no_rtg_dna_CartPole-v0_27-11-2017_20-55-26/1/log.txt\u001b[0m\n",
      "********** Iteration 0 ************\n",
      "----------------------------------------\n",
      "|               Time |            1.06 |\n",
      "|          Iteration |               0 |\n",
      "|      AverageReturn |            23.9 |\n",
      "|          StdReturn |            11.2 |\n",
      "|          MaxReturn |              58 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            23.9 |\n",
      "|           EpLenStd |            11.2 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |           1e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 1 ************\n",
      "----------------------------------------\n",
      "|               Time |            2.48 |\n",
      "|          Iteration |               1 |\n",
      "|      AverageReturn |            25.1 |\n",
      "|          StdReturn |            12.8 |\n",
      "|          MaxReturn |              76 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            25.1 |\n",
      "|           EpLenStd |            12.8 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        2.00e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 2 ************\n",
      "----------------------------------------\n",
      "|               Time |             3.4 |\n",
      "|          Iteration |               2 |\n",
      "|      AverageReturn |            25.2 |\n",
      "|          StdReturn |            17.6 |\n",
      "|          MaxReturn |             104 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            25.2 |\n",
      "|           EpLenStd |            17.6 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        3.04e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 3 ************\n",
      "----------------------------------------\n",
      "|               Time |            5.02 |\n",
      "|          Iteration |               3 |\n",
      "|      AverageReturn |            21.6 |\n",
      "|          StdReturn |            10.7 |\n",
      "|          MaxReturn |              67 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            21.6 |\n",
      "|           EpLenStd |            10.7 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        4.05e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 4 ************\n",
      "----------------------------------------\n",
      "|               Time |            6.07 |\n",
      "|          Iteration |               4 |\n",
      "|      AverageReturn |            21.2 |\n",
      "|          StdReturn |            10.1 |\n",
      "|          MaxReturn |              56 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            21.2 |\n",
      "|           EpLenStd |            10.1 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        5.07e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 5 ************\n",
      "----------------------------------------\n",
      "|               Time |            7.56 |\n",
      "|          Iteration |               5 |\n",
      "|      AverageReturn |            20.2 |\n",
      "|          StdReturn |            8.18 |\n",
      "|          MaxReturn |              44 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            20.2 |\n",
      "|           EpLenStd |            8.18 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        6.08e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 6 ************\n",
      "----------------------------------------\n",
      "|               Time |            8.78 |\n",
      "|          Iteration |               6 |\n",
      "|      AverageReturn |            21.4 |\n",
      "|          StdReturn |            9.79 |\n",
      "|          MaxReturn |              53 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            21.4 |\n",
      "|           EpLenStd |            9.79 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        7.08e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 7 ************\n",
      "----------------------------------------\n",
      "|               Time |            9.95 |\n",
      "|          Iteration |               7 |\n",
      "|      AverageReturn |            23.6 |\n",
      "|          StdReturn |            11.9 |\n",
      "|          MaxReturn |              62 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            23.6 |\n",
      "|           EpLenStd |            11.9 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |         8.1e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 8 ************\n",
      "----------------------------------------\n",
      "|               Time |            10.7 |\n",
      "|          Iteration |               8 |\n",
      "|      AverageReturn |            24.3 |\n",
      "|          StdReturn |            14.2 |\n",
      "|          MaxReturn |              73 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            24.3 |\n",
      "|           EpLenStd |            14.2 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        9.12e+03 |\n",
      "----------------------------------------\n",
      "********** Iteration 9 ************\n",
      "----------------------------------------\n",
      "|               Time |            12.6 |\n",
      "|          Iteration |               9 |\n",
      "|      AverageReturn |            22.1 |\n",
      "|          StdReturn |            13.4 |\n",
      "|          MaxReturn |              72 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            22.1 |\n",
      "|           EpLenStd |            13.4 |\n",
      "| TimestepsThisBatch |        1.04e+03 |\n",
      "|     TimestepsSoFar |        1.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 10 ************\n",
      "----------------------------------------\n",
      "|               Time |            14.7 |\n",
      "|          Iteration |              10 |\n",
      "|      AverageReturn |            24.8 |\n",
      "|          StdReturn |            11.8 |\n",
      "|          MaxReturn |              55 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            24.8 |\n",
      "|           EpLenStd |            11.8 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        1.12e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 11 ************\n",
      "----------------------------------------\n",
      "|               Time |            15.9 |\n",
      "|          Iteration |              11 |\n",
      "|      AverageReturn |            25.5 |\n",
      "|          StdReturn |            14.3 |\n",
      "|          MaxReturn |              69 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            25.5 |\n",
      "|           EpLenStd |            14.3 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        1.22e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 12 ************\n",
      "----------------------------------------\n",
      "|               Time |            17.3 |\n",
      "|          Iteration |              12 |\n",
      "|      AverageReturn |            26.5 |\n",
      "|          StdReturn |            17.9 |\n",
      "|          MaxReturn |             108 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            26.5 |\n",
      "|           EpLenStd |            17.9 |\n",
      "| TimestepsThisBatch |        1.06e+03 |\n",
      "|     TimestepsSoFar |        1.33e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 13 ************\n",
      "----------------------------------------\n",
      "|               Time |            18.7 |\n",
      "|          Iteration |              13 |\n",
      "|      AverageReturn |            27.9 |\n",
      "|          StdReturn |            18.1 |\n",
      "|          MaxReturn |              92 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            27.9 |\n",
      "|           EpLenStd |            18.1 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        1.43e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 14 ************\n",
      "----------------------------------------\n",
      "|               Time |            19.9 |\n",
      "|          Iteration |              14 |\n",
      "|      AverageReturn |            26.4 |\n",
      "|          StdReturn |            13.6 |\n",
      "|          MaxReturn |              68 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            26.4 |\n",
      "|           EpLenStd |            13.6 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        1.53e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 15 ************\n",
      "----------------------------------------\n",
      "|               Time |            22.7 |\n",
      "|          Iteration |              15 |\n",
      "|      AverageReturn |            23.4 |\n",
      "|          StdReturn |            12.3 |\n",
      "|          MaxReturn |              60 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            23.4 |\n",
      "|           EpLenStd |            12.3 |\n",
      "| TimestepsThisBatch |        1.00e+03 |\n",
      "|     TimestepsSoFar |        1.63e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 16 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            24.5 |\n",
      "|          Iteration |              16 |\n",
      "|      AverageReturn |            28.7 |\n",
      "|          StdReturn |            17.5 |\n",
      "|          MaxReturn |              99 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            28.7 |\n",
      "|           EpLenStd |            17.5 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        1.73e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 17 ************\n",
      "----------------------------------------\n",
      "|               Time |            26.6 |\n",
      "|          Iteration |              17 |\n",
      "|      AverageReturn |            25.9 |\n",
      "|          StdReturn |              12 |\n",
      "|          MaxReturn |              55 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            25.9 |\n",
      "|           EpLenStd |              12 |\n",
      "| TimestepsThisBatch |        1.04e+03 |\n",
      "|     TimestepsSoFar |        1.83e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 18 ************\n",
      "----------------------------------------\n",
      "|               Time |            28.1 |\n",
      "|          Iteration |              18 |\n",
      "|      AverageReturn |            25.9 |\n",
      "|          StdReturn |            15.3 |\n",
      "|          MaxReturn |              85 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            25.9 |\n",
      "|           EpLenStd |            15.3 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        1.93e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 19 ************\n",
      "----------------------------------------\n",
      "|               Time |            29.9 |\n",
      "|          Iteration |              19 |\n",
      "|      AverageReturn |            28.4 |\n",
      "|          StdReturn |            12.9 |\n",
      "|          MaxReturn |              59 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            28.4 |\n",
      "|           EpLenStd |            12.9 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        2.04e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 20 ************\n",
      "----------------------------------------\n",
      "|               Time |            31.3 |\n",
      "|          Iteration |              20 |\n",
      "|      AverageReturn |            23.7 |\n",
      "|          StdReturn |            12.1 |\n",
      "|          MaxReturn |              56 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            23.7 |\n",
      "|           EpLenStd |            12.1 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        2.14e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 21 ************\n",
      "----------------------------------------\n",
      "|               Time |              33 |\n",
      "|          Iteration |              21 |\n",
      "|      AverageReturn |            33.5 |\n",
      "|          StdReturn |            22.9 |\n",
      "|          MaxReturn |             109 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |            33.5 |\n",
      "|           EpLenStd |            22.9 |\n",
      "| TimestepsThisBatch |        1.00e+03 |\n",
      "|     TimestepsSoFar |        2.24e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 22 ************\n",
      "----------------------------------------\n",
      "|               Time |            34.5 |\n",
      "|          Iteration |              22 |\n",
      "|      AverageReturn |            26.2 |\n",
      "|          StdReturn |            13.2 |\n",
      "|          MaxReturn |              60 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            26.2 |\n",
      "|           EpLenStd |            13.2 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        2.34e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 23 ************\n",
      "----------------------------------------\n",
      "|               Time |            36.4 |\n",
      "|          Iteration |              23 |\n",
      "|      AverageReturn |            24.5 |\n",
      "|          StdReturn |            11.3 |\n",
      "|          MaxReturn |              70 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |            24.5 |\n",
      "|           EpLenStd |            11.3 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        2.44e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 24 ************\n",
      "----------------------------------------\n",
      "|               Time |              38 |\n",
      "|          Iteration |              24 |\n",
      "|      AverageReturn |              35 |\n",
      "|          StdReturn |            16.7 |\n",
      "|          MaxReturn |              77 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |              35 |\n",
      "|           EpLenStd |            16.7 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        2.54e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 25 ************\n",
      "----------------------------------------\n",
      "|               Time |            39.9 |\n",
      "|          Iteration |              25 |\n",
      "|      AverageReturn |            32.2 |\n",
      "|          StdReturn |            14.8 |\n",
      "|          MaxReturn |              67 |\n",
      "|          MinReturn |              17 |\n",
      "|          EpLenMean |            32.2 |\n",
      "|           EpLenStd |            14.8 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        2.65e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 26 ************\n",
      "----------------------------------------\n",
      "|               Time |              41 |\n",
      "|          Iteration |              26 |\n",
      "|      AverageReturn |            35.4 |\n",
      "|          StdReturn |            23.6 |\n",
      "|          MaxReturn |             104 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            35.4 |\n",
      "|           EpLenStd |            23.6 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        2.75e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 27 ************\n",
      "----------------------------------------\n",
      "|               Time |            43.9 |\n",
      "|          Iteration |              27 |\n",
      "|      AverageReturn |            30.3 |\n",
      "|          StdReturn |            16.9 |\n",
      "|          MaxReturn |              80 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |            30.3 |\n",
      "|           EpLenStd |            16.9 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        2.85e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 28 ************\n",
      "----------------------------------------\n",
      "|               Time |            45.2 |\n",
      "|          Iteration |              28 |\n",
      "|      AverageReturn |            30.5 |\n",
      "|          StdReturn |            17.5 |\n",
      "|          MaxReturn |              90 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            30.5 |\n",
      "|           EpLenStd |            17.5 |\n",
      "| TimestepsThisBatch |        1.00e+03 |\n",
      "|     TimestepsSoFar |        2.95e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 29 ************\n",
      "----------------------------------------\n",
      "|               Time |              46 |\n",
      "|          Iteration |              29 |\n",
      "|      AverageReturn |            28.1 |\n",
      "|          StdReturn |            14.5 |\n",
      "|          MaxReturn |              75 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            28.1 |\n",
      "|           EpLenStd |            14.5 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        3.05e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 30 ************\n",
      "----------------------------------------\n",
      "|               Time |            47.1 |\n",
      "|          Iteration |              30 |\n",
      "|      AverageReturn |            25.7 |\n",
      "|          StdReturn |            15.2 |\n",
      "|          MaxReturn |              72 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            25.7 |\n",
      "|           EpLenStd |            15.2 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        3.15e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 31 ************\n",
      "----------------------------------------\n",
      "|               Time |            47.9 |\n",
      "|          Iteration |              31 |\n",
      "|      AverageReturn |            30.4 |\n",
      "|          StdReturn |            19.6 |\n",
      "|          MaxReturn |             101 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            30.4 |\n",
      "|           EpLenStd |            19.6 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        3.25e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 32 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            49.1 |\n",
      "|          Iteration |              32 |\n",
      "|      AverageReturn |            30.2 |\n",
      "|          StdReturn |            15.2 |\n",
      "|          MaxReturn |              79 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |            30.2 |\n",
      "|           EpLenStd |            15.2 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        3.35e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 33 ************\n",
      "----------------------------------------\n",
      "|               Time |            50.3 |\n",
      "|          Iteration |              33 |\n",
      "|      AverageReturn |            37.8 |\n",
      "|          StdReturn |            19.3 |\n",
      "|          MaxReturn |             106 |\n",
      "|          MinReturn |              14 |\n",
      "|          EpLenMean |            37.8 |\n",
      "|           EpLenStd |            19.3 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        3.46e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 34 ************\n",
      "----------------------------------------\n",
      "|               Time |            52.1 |\n",
      "|          Iteration |              34 |\n",
      "|      AverageReturn |            27.9 |\n",
      "|          StdReturn |            13.6 |\n",
      "|          MaxReturn |              61 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            27.9 |\n",
      "|           EpLenStd |            13.6 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        3.56e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 35 ************\n",
      "----------------------------------------\n",
      "|               Time |            53.8 |\n",
      "|          Iteration |              35 |\n",
      "|      AverageReturn |            40.9 |\n",
      "|          StdReturn |            23.1 |\n",
      "|          MaxReturn |              98 |\n",
      "|          MinReturn |              12 |\n",
      "|          EpLenMean |            40.9 |\n",
      "|           EpLenStd |            23.1 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        3.66e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 36 ************\n",
      "----------------------------------------\n",
      "|               Time |            54.9 |\n",
      "|          Iteration |              36 |\n",
      "|      AverageReturn |            33.4 |\n",
      "|          StdReturn |            22.9 |\n",
      "|          MaxReturn |              97 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            33.4 |\n",
      "|           EpLenStd |            22.9 |\n",
      "| TimestepsThisBatch |        1.04e+03 |\n",
      "|     TimestepsSoFar |        3.76e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 37 ************\n",
      "----------------------------------------\n",
      "|               Time |            55.8 |\n",
      "|          Iteration |              37 |\n",
      "|      AverageReturn |            33.4 |\n",
      "|          StdReturn |            15.1 |\n",
      "|          MaxReturn |              68 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            33.4 |\n",
      "|           EpLenStd |            15.1 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        3.87e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 38 ************\n",
      "----------------------------------------\n",
      "|               Time |            56.8 |\n",
      "|          Iteration |              38 |\n",
      "|      AverageReturn |            33.6 |\n",
      "|          StdReturn |              20 |\n",
      "|          MaxReturn |              90 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            33.6 |\n",
      "|           EpLenStd |              20 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        3.97e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 39 ************\n",
      "----------------------------------------\n",
      "|               Time |            58.2 |\n",
      "|          Iteration |              39 |\n",
      "|      AverageReturn |            34.5 |\n",
      "|          StdReturn |            22.7 |\n",
      "|          MaxReturn |             115 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |            34.5 |\n",
      "|           EpLenStd |            22.7 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        4.07e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 40 ************\n",
      "----------------------------------------\n",
      "|               Time |            59.6 |\n",
      "|          Iteration |              40 |\n",
      "|      AverageReturn |            35.4 |\n",
      "|          StdReturn |            25.3 |\n",
      "|          MaxReturn |             144 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            35.4 |\n",
      "|           EpLenStd |            25.3 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        4.17e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 41 ************\n",
      "----------------------------------------\n",
      "|               Time |            60.9 |\n",
      "|          Iteration |              41 |\n",
      "|      AverageReturn |            32.5 |\n",
      "|          StdReturn |            16.3 |\n",
      "|          MaxReturn |              69 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            32.5 |\n",
      "|           EpLenStd |            16.3 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        4.27e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 42 ************\n",
      "----------------------------------------\n",
      "|               Time |            61.9 |\n",
      "|          Iteration |              42 |\n",
      "|      AverageReturn |            27.9 |\n",
      "|          StdReturn |            18.1 |\n",
      "|          MaxReturn |              82 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            27.9 |\n",
      "|           EpLenStd |            18.1 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        4.37e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 43 ************\n",
      "----------------------------------------\n",
      "|               Time |            63.3 |\n",
      "|          Iteration |              43 |\n",
      "|      AverageReturn |            35.9 |\n",
      "|          StdReturn |            33.8 |\n",
      "|          MaxReturn |             200 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            35.9 |\n",
      "|           EpLenStd |            33.8 |\n",
      "| TimestepsThisBatch |        1.15e+03 |\n",
      "|     TimestepsSoFar |        4.49e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 44 ************\n",
      "----------------------------------------\n",
      "|               Time |            64.5 |\n",
      "|          Iteration |              44 |\n",
      "|      AverageReturn |            31.2 |\n",
      "|          StdReturn |            17.8 |\n",
      "|          MaxReturn |              88 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |            31.2 |\n",
      "|           EpLenStd |            17.8 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        4.59e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 45 ************\n",
      "----------------------------------------\n",
      "|               Time |            65.6 |\n",
      "|          Iteration |              45 |\n",
      "|      AverageReturn |            37.6 |\n",
      "|          StdReturn |            22.4 |\n",
      "|          MaxReturn |             106 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            37.6 |\n",
      "|           EpLenStd |            22.4 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        4.69e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 46 ************\n",
      "----------------------------------------\n",
      "|               Time |            66.9 |\n",
      "|          Iteration |              46 |\n",
      "|      AverageReturn |            28.5 |\n",
      "|          StdReturn |            13.8 |\n",
      "|          MaxReturn |              68 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            28.5 |\n",
      "|           EpLenStd |            13.8 |\n",
      "| TimestepsThisBatch |        1.03e+03 |\n",
      "|     TimestepsSoFar |        4.79e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 47 ************\n",
      "----------------------------------------\n",
      "|               Time |            68.4 |\n",
      "|          Iteration |              47 |\n",
      "|      AverageReturn |            30.7 |\n",
      "|          StdReturn |            16.8 |\n",
      "|          MaxReturn |              79 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            30.7 |\n",
      "|           EpLenStd |            16.8 |\n",
      "| TimestepsThisBatch |        1.04e+03 |\n",
      "|     TimestepsSoFar |         4.9e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 48 ************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            69.4 |\n",
      "|          Iteration |              48 |\n",
      "|      AverageReturn |            40.4 |\n",
      "|          StdReturn |            25.8 |\n",
      "|          MaxReturn |             101 |\n",
      "|          MinReturn |              13 |\n",
      "|          EpLenMean |            40.4 |\n",
      "|           EpLenStd |            25.8 |\n",
      "| TimestepsThisBatch |        1.05e+03 |\n",
      "|     TimestepsSoFar |           5e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 49 ************\n",
      "----------------------------------------\n",
      "|               Time |            70.5 |\n",
      "|          Iteration |              49 |\n",
      "|      AverageReturn |            32.8 |\n",
      "|          StdReturn |              20 |\n",
      "|          MaxReturn |              84 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            32.8 |\n",
      "|           EpLenStd |              20 |\n",
      "| TimestepsThisBatch |        1.05e+03 |\n",
      "|     TimestepsSoFar |        5.11e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 50 ************\n",
      "----------------------------------------\n",
      "|               Time |            71.4 |\n",
      "|          Iteration |              50 |\n",
      "|      AverageReturn |              36 |\n",
      "|          StdReturn |              19 |\n",
      "|          MaxReturn |              74 |\n",
      "|          MinReturn |              14 |\n",
      "|          EpLenMean |              36 |\n",
      "|           EpLenStd |              19 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        5.21e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 51 ************\n",
      "----------------------------------------\n",
      "|               Time |            73.1 |\n",
      "|          Iteration |              51 |\n",
      "|      AverageReturn |            29.6 |\n",
      "|          StdReturn |            17.5 |\n",
      "|          MaxReturn |              76 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            29.6 |\n",
      "|           EpLenStd |            17.5 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        5.31e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 52 ************\n",
      "----------------------------------------\n",
      "|               Time |            74.7 |\n",
      "|          Iteration |              52 |\n",
      "|      AverageReturn |            33.5 |\n",
      "|          StdReturn |            13.8 |\n",
      "|          MaxReturn |              61 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            33.5 |\n",
      "|           EpLenStd |            13.8 |\n",
      "| TimestepsThisBatch |        1.00e+03 |\n",
      "|     TimestepsSoFar |        5.41e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 53 ************\n",
      "----------------------------------------\n",
      "|               Time |            76.4 |\n",
      "|          Iteration |              53 |\n",
      "|      AverageReturn |            29.1 |\n",
      "|          StdReturn |            14.3 |\n",
      "|          MaxReturn |              62 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            29.1 |\n",
      "|           EpLenStd |            14.3 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        5.51e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 54 ************\n",
      "----------------------------------------\n",
      "|               Time |            77.9 |\n",
      "|          Iteration |              54 |\n",
      "|      AverageReturn |            30.6 |\n",
      "|          StdReturn |            16.6 |\n",
      "|          MaxReturn |              64 |\n",
      "|          MinReturn |               9 |\n",
      "|          EpLenMean |            30.6 |\n",
      "|           EpLenStd |            16.6 |\n",
      "| TimestepsThisBatch |        1.04e+03 |\n",
      "|     TimestepsSoFar |        5.62e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 55 ************\n",
      "----------------------------------------\n",
      "|               Time |            79.4 |\n",
      "|          Iteration |              55 |\n",
      "|      AverageReturn |            32.7 |\n",
      "|          StdReturn |            17.5 |\n",
      "|          MaxReturn |              78 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            32.7 |\n",
      "|           EpLenStd |            17.5 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        5.72e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 56 ************\n",
      "----------------------------------------\n",
      "|               Time |            82.1 |\n",
      "|          Iteration |              56 |\n",
      "|      AverageReturn |            30.3 |\n",
      "|          StdReturn |            18.1 |\n",
      "|          MaxReturn |              93 |\n",
      "|          MinReturn |              10 |\n",
      "|          EpLenMean |            30.3 |\n",
      "|           EpLenStd |            18.1 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        5.82e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 57 ************\n",
      "----------------------------------------\n",
      "|               Time |            84.2 |\n",
      "|          Iteration |              57 |\n",
      "|      AverageReturn |            36.4 |\n",
      "|          StdReturn |            19.3 |\n",
      "|          MaxReturn |              75 |\n",
      "|          MinReturn |              11 |\n",
      "|          EpLenMean |            36.4 |\n",
      "|           EpLenStd |            19.3 |\n",
      "| TimestepsThisBatch |        1.02e+03 |\n",
      "|     TimestepsSoFar |        5.92e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 58 ************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k.p.osminin/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:171: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|               Time |            85.6 |\n",
      "|          Iteration |              58 |\n",
      "|      AverageReturn |            9.29 |\n",
      "|          StdReturn |           0.758 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.29 |\n",
      "|           EpLenStd |           0.758 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 59 ************\n",
      "----------------------------------------\n",
      "|               Time |            88.1 |\n",
      "|          Iteration |              59 |\n",
      "|      AverageReturn |            9.36 |\n",
      "|          StdReturn |           0.752 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.36 |\n",
      "|           EpLenStd |           0.752 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.12e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 60 ************\n",
      "----------------------------------------\n",
      "|               Time |            89.2 |\n",
      "|          Iteration |              60 |\n",
      "|      AverageReturn |            9.43 |\n",
      "|          StdReturn |           0.725 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.43 |\n",
      "|           EpLenStd |           0.725 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        6.22e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 61 ************\n",
      "----------------------------------------\n",
      "|               Time |            90.8 |\n",
      "|          Iteration |              61 |\n",
      "|      AverageReturn |            9.32 |\n",
      "|          StdReturn |           0.718 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.32 |\n",
      "|           EpLenStd |           0.718 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        6.32e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 62 ************\n",
      "----------------------------------------\n",
      "|               Time |            93.3 |\n",
      "|          Iteration |              62 |\n",
      "|      AverageReturn |            9.27 |\n",
      "|          StdReturn |           0.715 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.27 |\n",
      "|           EpLenStd |           0.715 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.42e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 63 ************\n",
      "----------------------------------------\n",
      "|               Time |            94.2 |\n",
      "|          Iteration |              63 |\n",
      "|      AverageReturn |            9.45 |\n",
      "|          StdReturn |           0.779 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.45 |\n",
      "|           EpLenStd |           0.779 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.52e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 64 ************\n",
      "----------------------------------------\n",
      "|               Time |            95.6 |\n",
      "|          Iteration |              64 |\n",
      "|      AverageReturn |            9.29 |\n",
      "|          StdReturn |           0.746 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.29 |\n",
      "|           EpLenStd |           0.746 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.62e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 65 ************\n",
      "----------------------------------------\n",
      "|               Time |              97 |\n",
      "|          Iteration |              65 |\n",
      "|      AverageReturn |            9.34 |\n",
      "|          StdReturn |           0.772 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.34 |\n",
      "|           EpLenStd |           0.772 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        6.72e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 66 ************\n",
      "----------------------------------------\n",
      "|               Time |            98.1 |\n",
      "|          Iteration |              66 |\n",
      "|      AverageReturn |            9.41 |\n",
      "|          StdReturn |           0.761 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.41 |\n",
      "|           EpLenStd |           0.761 |\n",
      "| TimestepsThisBatch |        1.01e+03 |\n",
      "|     TimestepsSoFar |        6.82e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 67 ************\n",
      "----------------------------------------\n",
      "|               Time |            99.4 |\n",
      "|          Iteration |              67 |\n",
      "|      AverageReturn |            9.36 |\n",
      "|          StdReturn |           0.687 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.36 |\n",
      "|           EpLenStd |           0.687 |\n",
      "| TimestepsThisBatch |           1e+03 |\n",
      "|     TimestepsSoFar |        6.92e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 68 ************\n",
      "----------------------------------------\n",
      "|               Time |             101 |\n",
      "|          Iteration |              68 |\n",
      "|      AverageReturn |            9.31 |\n",
      "|          StdReturn |           0.726 |\n",
      "|          MaxReturn |              11 |\n",
      "|          MinReturn |               8 |\n",
      "|          EpLenMean |            9.31 |\n",
      "|           EpLenStd |           0.726 |\n",
      "| TimestepsThisBatch |        1.00e+03 |\n",
      "|     TimestepsSoFar |        7.02e+04 |\n",
      "----------------------------------------\n",
      "********** Iteration 69 ************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dc76c0ab8413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-dc76c0ab8413>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 )\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-dc76c0ab8413>\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m                 )\n\u001b[1;32m    424\u001b[0m         \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-dc76c0ab8413>\u001b[0m in \u001b[0;36mtrain_PG\u001b[0;34m(exp_name, env_name, n_iter, gamma, min_timesteps_per_batch, max_path_length, learning_rate, reward_to_go, animate, logdir, normalize_advantages, nn_baseline, seed, n_layers, size)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;31m#TODO: CHECK_IT!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mac_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# Pick action according to mlp policy. mlp output is actions logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k.p.osminin/miniconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a576475ae685>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# Last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#         x = self.activation(self.fc[0](x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k.p.osminin/miniconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k.p.osminin/miniconda2/lib/python2.7/site-packages/torch/nn/_functions/thnn/auto.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, *params)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#============================================================================================#\n",
    "# Policy Gradient\n",
    "#============================================================================================#\n",
    "\n",
    "def train_PG(exp_name='',\n",
    "             env_name='CartPole-v0',\n",
    "             n_iter=100,\n",
    "             gamma=1.0,\n",
    "             min_timesteps_per_batch=1000,\n",
    "             max_path_length=None,\n",
    "             learning_rate=5e-3,\n",
    "             reward_to_go=True,\n",
    "             animate=True,\n",
    "             logdir=None,\n",
    "             normalize_advantages=True,\n",
    "             nn_baseline=False,\n",
    "             seed=0,\n",
    "             # network arguments\n",
    "             n_layers=1,\n",
    "             size=32\n",
    "             ):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Configure output directory for logging\n",
    "    logz.configure_output_dir(logdir)\n",
    "\n",
    "    # Log experimental parameters\n",
    "    #args = inspect.getfullargspec(train_PG)[0]\n",
    "    args = inspect.getargspec(train_PG)[0]\n",
    "    locals_ = locals()\n",
    "    params = {k: locals_[k] if k in locals_ else None for k in args}\n",
    "    logz.save_params(params)\n",
    "\n",
    "    # Set random seeds\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Make the gym environment\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "    # Is this env continuous, or discrete?\n",
    "    discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
    "\n",
    "    # Maximum length for episodes\n",
    "    max_path_length = max_path_length or env.spec.max_episode_steps\n",
    "\n",
    "    #========================================================================================#\n",
    "    # Notes on notation:\n",
    "    #\n",
    "    # Symbolic variables have the prefix sy_, to distinguish them from the numerical values\n",
    "    # that are computed later in the function\n",
    "    #\n",
    "    # Prefixes and suffixes:\n",
    "    # ob - observation\n",
    "    # ac - action\n",
    "    # _no - this tensor should have shape (batch size /n/, observation dim)\n",
    "    # _na - this tensor should have shape (batch size /n/, action dim)\n",
    "    # _n  - this tensor should have shape (batch size /n/)\n",
    "    #\n",
    "    # Note: batch size /n/ is defined at runtime, and until then, the shape for that axis\n",
    "    # is None\n",
    "    #========================================================================================#\n",
    "\n",
    "    # Observation and action sizes\n",
    "    ob_dim = env.observation_space.shape[0]\n",
    "    ac_dim = env.action_space.n if discrete else env.action_space.shape[0]\n",
    "\n",
    "    #TODO: REMOVE\n",
    "    # #========================================================================================#\n",
    "    # #                           ----------SECTION 4----------\n",
    "    # # Networks\n",
    "    # #\n",
    "    # # Make symbolic operations for\n",
    "    # #   1. Policy network outputs which describe the policy distribution.\n",
    "    # #       a. For the discrete case, just logits for each action.\n",
    "    # #\n",
    "    # #       b. For the continuous case, the mean / log std of a Gaussian distribution over\n",
    "    # #          actions.\n",
    "    # #\n",
    "    # #      Hint: use the 'build_mlp' function you defined in utilities.\n",
    "    # #\n",
    "    # #\n",
    "    # #   2. Producing samples stochastically from the policy distribution.\n",
    "    # #       a. For the discrete case, an op that takes in logits and produces actions.\n",
    "    # #\n",
    "    # #          Should have shape [None]\n",
    "    # #\n",
    "    # #       b. For the continuous case, use the reparameterization trick:\n",
    "    # #          The output from a Gaussian distribution with mean 'mu' and std 'sigma' is\n",
    "    # #\n",
    "    # #               mu + sigma * z,         z ~ N(0, I)\n",
    "    # #\n",
    "    # #          This reduces the problem to just sampling z. (Hint: use random_normal!)\n",
    "    # #\n",
    "    # #          Should have shape [None, ac_dim]\n",
    "    # #\n",
    "    # #      Note: these ops should be functions of the policy network output ops.\n",
    "    # #\n",
    "    # #   3. Computing the log probability of a set of actions that were actually taken,\n",
    "    # #      according to the policy.\n",
    "    # #\n",
    "    # #\n",
    "    # #========================================================================================#\n",
    "    #\n",
    "    # if discrete:\n",
    "    #     # YOUR_CODE_HERE\n",
    "    #     sy_logits_na = TODO\n",
    "    #     sy_sampled_ac = TODO # Hint: Use the multinomial op\n",
    "    #     sy_logprob_n = TODO\n",
    "    #\n",
    "    # else:\n",
    "    #     # YOUR_CODE_HERE\n",
    "    #     sy_mean = TODO\n",
    "    #     sy_logstd = TODO # logstd should just be a trainable variable, not a network output.\n",
    "    #     sy_sampled_ac = TODO\n",
    "    #     sy_logprob_n = TODO  # Hint: Use the log probability under a multivariate gaussian.\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 4----------\n",
    "    # Loss Function and Training Operation\n",
    "    #========================================================================================#\n",
    "\n",
    "    mlp = MLP(input_size = ob_dim, output_size = ac_dim, \n",
    "              n_layers = n_layers, size = size,output_activation=F.softmax)\n",
    "#     loss = TODO # Loss function that we'll differentiate to get the policy gradient.\n",
    "    update_op = optim.Adam(mlp.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    #                           ----------SECTION 5----------\n",
    "    # Optional Baseline\n",
    "    #========================================================================================#\n",
    "\n",
    "    if nn_baseline:\n",
    "        mlp_baseline = MLP(ob_dim, 1, n_layers=n_layers, size=size,output_activation=F.linear)\n",
    "        update_baseline_op = optim.Adam(mlp_baseline.parameters(), lr=learning_rate)\n",
    "        q_prev_mean, q_prev_std = 0., 1.\n",
    "\n",
    "\n",
    "    #========================================================================================#\n",
    "    # Training Loop\n",
    "    #========================================================================================#\n",
    "\n",
    "    total_timesteps = 0\n",
    "\n",
    "    for itr in range(n_iter):\n",
    "        print(\"********** Iteration %i ************\"%itr)\n",
    "\n",
    "        # Collect paths until we have enough timesteps\n",
    "        timesteps_this_batch = 0\n",
    "        paths = []\n",
    "        while True:\n",
    "            ob = env.reset()\n",
    "            obs, acs, rewards = [], [], []\n",
    "            animate_this_episode=(len(paths)==0 and (itr % 10 == 0) and animate)\n",
    "            steps = 0\n",
    "            while True:\n",
    "                if animate_this_episode:\n",
    "                    env.render()\n",
    "                    time.sleep(0.05)\n",
    "                obs.append(ob)\n",
    "\n",
    "                #TODO: CHECK_IT!\n",
    "                ac_logits = mlp(Variable(torch.Tensor(ob[None]))).data.numpy()[0,:]\n",
    "                \n",
    "                # Pick action according to mlp policy. mlp output is actions logits\n",
    "                # ac_probs is one-dim vector for one observation, not batch!\n",
    "                ac_probs = 1. / (1 + np.exp( -ac_logits))\n",
    "                ac_probs = ac_probs / ac_probs.sum()\n",
    "                ac = np.random.choice(range(ac_dim), p = ac_probs)\n",
    "                \n",
    "                #ac = ac[0]\n",
    "                acs.append(ac)\n",
    "\n",
    "                ob, rew, done, _ = env.step(ac)\n",
    "                rewards.append(rew)\n",
    "                steps += 1\n",
    "                if done or steps > max_path_length:\n",
    "                    break\n",
    "            path = {\"observation\" : np.array(obs),\n",
    "                    \"reward\" : np.array(rewards),\n",
    "                    \"action\" : np.array(acs)}\n",
    "            paths.append(path)\n",
    "            timesteps_this_batch += pathlength(path)\n",
    "            if timesteps_this_batch > min_timesteps_per_batch:\n",
    "                break\n",
    "        total_timesteps += timesteps_this_batch\n",
    "\n",
    "        # Build arrays for observation, action for the policy gradient update by concatenating\n",
    "        # across paths\n",
    "        ob_no = np.concatenate([path[\"observation\"] for path in paths])\n",
    "        ac_na = np.concatenate([path[\"action\"] for path in paths])\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Computing Q-values\n",
    "        #\n",
    "        # Your code should construct numpy arrays for Q-values which will be used to compute\n",
    "        # advantages.\n",
    "        #\n",
    "        # Recall that the expression for the policy gradient PG is\n",
    "        #\n",
    "        #       PG = E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * (Q_t - b_t )]\n",
    "        #\n",
    "        # where\n",
    "        #\n",
    "        #       tau=(s_0, a_0, ...) is a trajectory,\n",
    "        #       Q_t is the Q-value at time t, Q^{pi}(s_t, a_t),\n",
    "        #       and b_t is a baseline which may depend on s_t.\n",
    "        #\n",
    "        # You will write code for two cases, controlled by the flag 'reward_to_go':\n",
    "        #\n",
    "        #   Case 1: trajectory-based PG\n",
    "        #\n",
    "        #       (reward_to_go = False)\n",
    "        #\n",
    "        #       Instead of Q^{pi}(s_t, a_t), we use the total discounted reward summed over\n",
    "        #       entire trajectory (regardless of which time step the Q-value should be for).\n",
    "        #\n",
    "        #       For this case, the policy gradient estimator is\n",
    "        #\n",
    "        #           E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * Ret(tau)]\n",
    "        #\n",
    "        #       where\n",
    "        #\n",
    "        #           Ret(tau) = sum_{t'=0}^T gamma^t' r_{t'}.\n",
    "        #\n",
    "        #       Thus, you should compute\n",
    "        #\n",
    "        #           Q_t = Ret(tau)\n",
    "        #\n",
    "        #   Case 2: reward-to-go PG\n",
    "        #\n",
    "        #       (reward_to_go = True)\n",
    "        #\n",
    "        #       Here, you estimate Q^{pi}(s_t, a_t) by the discounted sum of rewards starting\n",
    "        #       from time step t. Thus, you should compute\n",
    "        #\n",
    "        #           Q_t = sum_{t'=t}^T gamma^(t'-t) * r_{t'}\n",
    "        #\n",
    "        #\n",
    "        # Store the Q-values for all timesteps and all trajectories in a variable 'q_n',\n",
    "        # like the 'ob_no' and 'ac_na' above.\n",
    "        #\n",
    "        #====================================================================================#\n",
    "\n",
    "        # YOUR_CODE_HERE\n",
    "        if reward_to_go:\n",
    "            q_n = np.concatenate([\n",
    "                                    np.cumsum([r * gamma ** i for i,r in enumerate(path[\"reward\"])][::-1])[::-1]                \n",
    "                                 for path in paths])\n",
    "        else:            \n",
    "            q_n = np.concatenate([\n",
    "                                    [sum([r * gamma ** i for i,r in enumerate(path[\"reward\"])])] \n",
    "                                        * len(path[\"reward\"]) \n",
    "                                 for path in paths])\n",
    "            \n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 5----------\n",
    "        # Computing Baselines\n",
    "        #====================================================================================#\n",
    "\n",
    "        if nn_baseline:\n",
    "            # If nn_baseline is True, use your neural network to predict reward-to-go\n",
    "            # at each timestep for each trajectory, and save the result in a variable 'b_n'\n",
    "            # like 'ob_no', 'ac_na', and 'q_n'.\n",
    "            #\n",
    "            # Hint #bl1: rescale the output from the nn_baseline to match the statistics\n",
    "            # (mean and std) of the current or previous batch of Q-values. (Goes with Hint\n",
    "            # #bl2 below.)\n",
    "            v_n = mlp_baseline(Variable(torch.Tensor(ob_no)))[:,0]\n",
    "            b_n = (v_n.data.numpy() + q_prev_mean) * q_prev_std\n",
    "            adv_n = q_n - b_n\n",
    "            q_prev_mean, q_prev_std = q_n.mean(),q_n.std()\n",
    "            \n",
    "        else:\n",
    "            adv_n = q_n.copy()\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Advantage Normalization\n",
    "        #====================================================================================#\n",
    "\n",
    "        if normalize_advantages:\n",
    "            # On the next line, implement a trick which is known empirically to reduce variance\n",
    "            # in policy gradient methods: normalize adv_n to have mean zero and std=1.\n",
    "            # YOUR_CODE_HERE\n",
    "            adv_n = (adv_n - adv_n.mean())/(adv_n.std() + 1e-15)\n",
    "\n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 5----------\n",
    "        # Optimizing Neural Network Baseline\n",
    "        #====================================================================================#\n",
    "\n",
    "        if nn_baseline:\n",
    "            # ----------SECTION 5----------\n",
    "            # If a neural network baseline is used, set up the targets and the inputs for the\n",
    "            # baseline.\n",
    "            #\n",
    "            # Fit it to the current batch in order to use for the next iteration. Use the\n",
    "            # baseline_update_op you defined earlier.\n",
    "            #\n",
    "            # Hint #bl2: Instead of trying to target raw Q-values directly, rescale the\n",
    "            # targets to have mean zero and std=1. (Goes with Hint #bl1 above.)\n",
    "\n",
    "            baseline_loss = (v_n - Variable(torch.Tensor((q_n-q_n.mean())/q_n.std()))**2).mean()\n",
    "            update_baseline_op.zero_grad()\n",
    "            baseline_loss.backward()\n",
    "            update_baseline_op.step()\n",
    "            \n",
    "\n",
    "        #====================================================================================#\n",
    "        #                           ----------SECTION 4----------\n",
    "        # Performing the Policy Update\n",
    "        #====================================================================================#\n",
    "\n",
    "        # Call the update operation necessary to perform the policy gradient update based on\n",
    "        # the current batch of rollouts.\n",
    "        #\n",
    "        # For debug purposes, you may wish to save the value of the loss function before\n",
    "        # and after an update, and then log them below.\n",
    "\n",
    "#         PG = E_{tau} [sum_{t=0}^T grad log pi(a_t|s_t) * (Q_t - b_t )]\n",
    "        # YOUR_CODE_HERE\n",
    "\n",
    "        #Another solution\n",
    "#         a,ac,a.view(-1)[torch.LongTensor(ac+3*np.arange(20))]\n",
    "        adv_var = torch.autograd.Variable(torch.FloatTensor(adv_n) , requires_grad=False)\n",
    "    \n",
    "        actions_t = torch.LongTensor(ac_na+ac_dim*np.arange(ob_no.shape[0]))         \n",
    "        PGI = - (torch.log(mlp(Variable(torch.Tensor(ob_no))).view(-1)[actions_t]) * adv_var).sum() / len(paths)\n",
    "        update_op.zero_grad()\n",
    "        PGI.backward()\n",
    "        update_op.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        # Log diagnostics\n",
    "        returns = [path[\"reward\"].sum() for path in paths]\n",
    "        ep_lengths = [pathlength(path) for path in paths]\n",
    "        logz.log_tabular(\"Time\", time.time() - start)\n",
    "        logz.log_tabular(\"Iteration\", itr)\n",
    "        logz.log_tabular(\"AverageReturn\", np.mean(returns))\n",
    "        logz.log_tabular(\"StdReturn\", np.std(returns))\n",
    "        logz.log_tabular(\"MaxReturn\", np.max(returns))\n",
    "        logz.log_tabular(\"MinReturn\", np.min(returns))\n",
    "        logz.log_tabular(\"EpLenMean\", np.mean(ep_lengths))\n",
    "        logz.log_tabular(\"EpLenStd\", np.std(ep_lengths))\n",
    "        logz.log_tabular(\"TimestepsThisBatch\", timesteps_this_batch)\n",
    "        logz.log_tabular(\"TimestepsSoFar\", total_timesteps)\n",
    "        logz.dump_tabular()\n",
    "\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('env_name', type=str)\n",
    "#     parser.add_argument('--exp_name', type=str, default='vpg')\n",
    "#     parser.add_argument('--render', action='store_true')\n",
    "#     parser.add_argument('--discount', type=float, default=1.0)\n",
    "#     parser.add_argument('--n_iter', '-n', type=int, default=100)\n",
    "#     parser.add_argument('--batch_size', '-b', type=int, default=1000)\n",
    "#     parser.add_argument('--ep_len', '-ep', type=float, default=-1.)\n",
    "#     parser.add_argument('--learning_rate', '-lr', type=float, default=5e-3)\n",
    "#     parser.add_argument('--reward_to_go', '-rtg', action='store_true')\n",
    "#     parser.add_argument('--dont_normalize_advantages', '-dna', action='store_true')\n",
    "#     parser.add_argument('--nn_baseline', '-bl', action='store_true')\n",
    "#     parser.add_argument('--seed', type=int, default=1)\n",
    "#     parser.add_argument('--n_experiments', '-e', type=int, default=1)\n",
    "#     parser.add_argument('--n_layers', '-l', type=int, default=1)\n",
    "#     parser.add_argument('--size', '-s', type=int, default=32)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    args = pd.Series()\n",
    "    args.batch_size=1000\n",
    "    args.discount=1.0\n",
    "    args.dont_normalize_advantages=False\n",
    "    args.env_name='CartPole-v0'\n",
    "    args.ep_len=-1.0\n",
    "    args.exp_name='sb_no_rtg_dna'\n",
    "    args.learning_rate=5e-3\n",
    "    args.n_experiments=5\n",
    "    args.n_iter=100\n",
    "    args.n_layers=1\n",
    "    args.nn_baseline=False\n",
    "    args.render=False\n",
    "    args.reward_to_go=True\n",
    "    args.seed=1\n",
    "    args.size_=32\n",
    "\n",
    "                \n",
    "    if not(os.path.exists('data')):\n",
    "        os.makedirs('data')\n",
    "    logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    logdir = os.path.join('data', logdir)\n",
    "    if not(os.path.exists(logdir)):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    max_path_length = args.ep_len if args.ep_len > 0 else None\n",
    "\n",
    "    for e in range(args.n_experiments):\n",
    "        seed = args.seed + 10*e\n",
    "        print('Running experiment with seed %d'%seed)\n",
    "        def train_func():\n",
    "            train_PG(\n",
    "                exp_name=args.exp_name,\n",
    "                env_name=args.env_name,\n",
    "                n_iter=args.n_iter,\n",
    "                gamma=args.discount,\n",
    "                min_timesteps_per_batch=args.batch_size,\n",
    "                max_path_length=max_path_length,\n",
    "                learning_rate=args.learning_rate,\n",
    "                reward_to_go=args.reward_to_go,\n",
    "                animate=args.render,\n",
    "                logdir=os.path.join(logdir,'%d'%seed),\n",
    "                normalize_advantages=not(args.dont_normalize_advantages),\n",
    "                nn_baseline=args.nn_baseline,\n",
    "                seed=seed,\n",
    "                n_layers=args.n_layers,\n",
    "                size=args.size_\n",
    "                )\n",
    "        train_func()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
